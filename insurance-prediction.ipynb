{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-27T05:38:02.808153Z","iopub.execute_input":"2021-10-27T05:38:02.808566Z","iopub.status.idle":"2021-10-27T05:38:02.844969Z","shell.execute_reply.started":"2021-10-27T05:38:02.808467Z","shell.execute_reply":"2021-10-27T05:38:02.843870Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/input/prudential-life-insurance-assessment\n!cp train.csv.zip /kaggle\n!cp test.csv.zip /kaggle\n%cd /kaggle\n!ls\n!unzip train.csv.zip\n!unzip test.csv.zip","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:02.847259Z","iopub.execute_input":"2021-10-27T05:38:02.848031Z","iopub.status.idle":"2021-10-27T05:38:06.958357Z","shell.execute_reply.started":"2021-10-27T05:38:02.847984Z","shell.execute_reply":"2021-10-27T05:38:06.957545Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"train.csv\")\ntest_df = pd.read_csv(\"test.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:06.960124Z","iopub.execute_input":"2021-10-27T05:38:06.960632Z","iopub.status.idle":"2021-10-27T05:38:07.956000Z","shell.execute_reply.started":"2021-10-27T05:38:06.960597Z","shell.execute_reply":"2021-10-27T05:38:07.955107Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# 觀察train data\n\nprint(train_df.shape)\nprint(\"我們共有 {} 筆訓練資料，包含 {} 特徵\".format(train_df.shape[0], train_df.shape[1]))\nprint(\"測試資料有 {} 筆\".format(test_df.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:07.958226Z","iopub.execute_input":"2021-10-27T05:38:07.958516Z","iopub.status.idle":"2021-10-27T05:38:07.965758Z","shell.execute_reply.started":"2021-10-27T05:38:07.958484Z","shell.execute_reply":"2021-10-27T05:38:07.964894Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:07.967441Z","iopub.execute_input":"2021-10-27T05:38:07.967955Z","iopub.status.idle":"2021-10-27T05:38:08.424352Z","shell.execute_reply.started":"2021-10-27T05:38:07.967884Z","shell.execute_reply":"2021-10-27T05:38:08.423436Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport plotly.express as px\n\n# feature 大多為 numerical. 我們目標 Response 有 8 個 level, 先觀察 Response\n\nplt.hist(train_df[\"Response\"])\nplt.title(\"Train data Response distribution\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:08.425877Z","iopub.execute_input":"2021-10-27T05:38:08.426792Z","iopub.status.idle":"2021-10-27T05:38:10.494576Z","shell.execute_reply.started":"2021-10-27T05:38:08.426746Z","shell.execute_reply":"2021-10-27T05:38:10.493506Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"#### 目標metric為quadratic weighted kappa分數","metadata":{}},{"cell_type":"code","source":"# 資料為保險申請人的資料\n# 由圖可見風險分數高的申請人較多，再來是風險較低的，最後是風險中間值的\n# 讓我們來觀察描述資料中的特徵\n\n# Product_info 1_6: features relating to the applied product, 然而不知道內容 \n\n# feature may interested: age, BMI, employment history, applicant info, insurance history\n# family history, medical history\n\ntrain_df.boxplot(\"Ins_Age\", by = \"Response\")\nplt.suptitle(\"\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:10.496006Z","iopub.execute_input":"2021-10-27T05:38:10.496280Z","iopub.status.idle":"2021-10-27T05:38:11.098915Z","shell.execute_reply.started":"2021-10-27T05:38:10.496216Z","shell.execute_reply":"2021-10-27T05:38:11.097962Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 看來Response風險最低的年齡級距最大，接著隨風險值的增加年齡緩慢降低。風險值>5後，年齡均值和級距又增加\n\n# 觀察BMI:\ntrain_df.boxplot(\"BMI\", by = \"Response\")\nplt.suptitle(\"\")","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:11.100491Z","iopub.execute_input":"2021-10-27T05:38:11.101162Z","iopub.status.idle":"2021-10-27T05:38:11.501284Z","shell.execute_reply.started":"2021-10-27T05:38:11.101111Z","shell.execute_reply":"2021-10-27T05:38:11.500377Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 接著觀察employment feature: categorical variable\n\n# Employment feature:\nemploy_hist = [col for col in train_df.columns if \"Employ\" in col]\ntrain_df[employ_hist]","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:11.502801Z","iopub.execute_input":"2021-10-27T05:38:11.503033Z","iopub.status.idle":"2021-10-27T05:38:11.525311Z","shell.execute_reply.started":"2021-10-27T05:38:11.503007Z","shell.execute_reply":"2021-10-27T05:38:11.524086Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Data cleaning\nis_null = train_df.isnull().sum()\nis_null = is_null[is_null > 0]\nis_null.sort_values(ascending = False, inplace = True)\n\nprint(is_null)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:42:52.911250Z","iopub.execute_input":"2021-10-27T05:42:52.911545Z","iopub.status.idle":"2021-10-27T05:42:52.938959Z","shell.execute_reply.started":"2021-10-27T05:42:52.911517Z","shell.execute_reply":"2021-10-27T05:42:52.937687Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"\n\n# remove columns with too much missing value\nnull_feature = is_null[is_null > len(train_df)//2].index\nprint(\"Drop {} features: \".format(len(null_feature), null_feature))\ntrain_df.drop(null_feature, axis = 1, inplace = True)\n\nprint(\"Null feature after dropping:\")\nis_null = train_df.isnull().sum()\nis_null = is_null[is_null > 0]\nis_null.sort_values(ascending = False, inplace = True)\nprint(is_null)\n\nprint(\"Left {} features\".format(train_df.shape[1]))","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:45:50.305736Z","iopub.execute_input":"2021-10-27T05:45:50.306858Z","iopub.status.idle":"2021-10-27T05:45:50.378444Z","shell.execute_reply.started":"2021-10-27T05:45:50.306814Z","shell.execute_reply":"2021-10-27T05:45:50.377672Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# impute missing value \n\n# Family_Hist: continuous\n# Insurance History: categorical(nominal without order)\n# Employmeint Info: categorical(No Order)\n# Medical history: categorical(No Order)\n\n# Easy impute: fill continuous with median, categorical with freq. value\nfrom sklearn.impute import SimpleImputer\n\nnum_imp = SimpleImputer(missing_values = np.nan, strategy = \"median\")\ncat_imp = SimpleImputer(missing_values = np.nan, strategy = \"most_frequent\")\n\nnum_null_feature = [\"Family_Hist_2\", \"Family_Hist_4\"]\ncat_null_feature = [\"Employment_Info_1\", \"Employment_Info_4\", \"Employment_Info_6\",\\\n                   \"Medical_History_1\", \"Insurance_History_5\"]\n\ntrain_df[num_null_feature] = num_imp.fit_transform(train_df[num_null_feature])\ntrain_df[cat_null_feature] = cat_imp.fit_transform(train_df[cat_null_feature])\n\nprint(\"After impute:\")\nis_null = train_df.isnull().sum()\nis_null = is_null[is_null > 0]\nis_null.sort_values(ascending = False, inplace = True)\nprint(is_null)","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:05:57.287619Z","iopub.execute_input":"2021-10-27T06:05:57.287954Z","iopub.status.idle":"2021-10-27T06:05:57.358562Z","shell.execute_reply.started":"2021-10-27T06:05:57.287923Z","shell.execute_reply":"2021-10-27T06:05:57.357908Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:58:20.030736Z","iopub.execute_input":"2021-10-27T05:58:20.031040Z","iopub.status.idle":"2021-10-27T05:58:20.285596Z","shell.execute_reply.started":"2021-10-27T05:58:20.031010Z","shell.execute_reply":"2021-10-27T05:58:20.284881Z"}}},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:12:18.922248Z","iopub.execute_input":"2021-10-27T06:12:18.922589Z","iopub.status.idle":"2021-10-27T06:12:19.331528Z","shell.execute_reply.started":"2021-10-27T06:12:18.922558Z","shell.execute_reply":"2021-10-27T06:12:19.330353Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_df.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:28:58.862972Z","iopub.execute_input":"2021-10-27T06:28:58.863294Z","iopub.status.idle":"2021-10-27T06:28:58.873268Z","shell.execute_reply.started":"2021-10-27T06:28:58.863263Z","shell.execute_reply":"2021-10-27T06:28:58.872529Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Data preprocessing\n\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\n\n# Encode all features to numerical\nencoder = LabelEncoder()\ntrain_df.Product_Info_2 = encoder.fit_transform(train_df.Product_Info_2)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T06:46:08.936146Z","iopub.execute_input":"2021-10-27T06:46:08.936512Z","iopub.status.idle":"2021-10-27T06:46:09.515412Z","shell.execute_reply.started":"2021-10-27T06:46:08.936475Z","shell.execute_reply":"2021-10-27T06:46:09.514244Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"# normalization\n\nnorm_feature = list(train_df.columns)\nnorm_feature = [elem for elem in norm_feature if elem not in [\"Id\", \"Response\"]]\n\nscaler = MinMaxScaler()\ntrain_df[norm_feature].values[:] = scaler.fit_transform(train_df[norm_feature])\ntrain_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T07:12:50.839152Z","iopub.execute_input":"2021-10-27T07:12:50.839967Z","iopub.status.idle":"2021-10-27T07:12:51.434589Z","shell.execute_reply.started":"2021-10-27T07:12:50.839924Z","shell.execute_reply":"2021-10-27T07:12:51.433393Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_df[norm_feature].columns","metadata":{"execution":{"iopub.status.busy":"2021-10-27T07:16:07.178492Z","iopub.execute_input":"2021-10-27T07:16:07.178850Z","iopub.status.idle":"2021-10-27T07:16:07.212882Z","shell.execute_reply.started":"2021-10-27T07:16:07.178814Z","shell.execute_reply":"2021-10-27T07:16:07.211570Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"sub_df = train_df[[\"Product_Info_2\", \"Product_Info_6\"]]\n#sub_df = train_df[norm_feature]\nprint(sub_df.describe())\n\nsub_df.values[:] = scaler.fit_transform(sub_df)\nsub_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-10-27T07:30:28.949291Z","iopub.execute_input":"2021-10-27T07:30:28.950500Z","iopub.status.idle":"2021-10-27T07:30:28.991024Z","shell.execute_reply.started":"2021-10-27T07:30:28.950437Z","shell.execute_reply":"2021-10-27T07:30:28.989947Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# 不了解employment feature 內容，直接開始建模\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression, SVR\n\n\n# Split train-test data\ny = train_df[\"Response\"]\nx = train_df.drop([\"Id\",\"Response\"], axis = 1)\n\nx_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size = 0.2)\n\nlogit = LogisticRegression(class_weight = \"balanced\")\nlogit.fit(x_train, y_train)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-10-27T05:38:11.655546Z","iopub.execute_input":"2021-10-27T05:38:11.655780Z","iopub.status.idle":"2021-10-27T05:38:11.662655Z","shell.execute_reply.started":"2021-10-27T05:38:11.655755Z","shell.execute_reply":"2021-10-27T05:38:11.661359Z"},"trusted":true},"execution_count":14,"outputs":[]}]}