{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ashrae_predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/Kaggle_competition/blob/master/Ashrae_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9Vn9mfylThK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import sklearn\n",
        "import lightgbm as lgb\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "import gc\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Siz69XRhL0km",
        "colab_type": "code",
        "outputId": "c464354f-877f-479b-b625-76a476a3cc46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# load data from Cloud Storage\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Configure GCP project and use gsutil to copy the file from storage\n",
        "!gcloud config set project 'blind-detection'\n",
        "!gsutil cp -r gs://ashare_dataset/*.csv  sample_data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Copying gs://ashare_dataset/building_metadata.csv...\n",
            "Copying gs://ashare_dataset/sample_submission.csv...\n",
            "Copying gs://ashare_dataset/test.csv...\n",
            "Copying gs://ashare_dataset/train.csv...\n",
            "\\ [4 files][  2.4 GiB/  2.4 GiB]  111.0 MiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://ashare_dataset/weather_test.csv...\n",
            "Copying gs://ashare_dataset/weather_train.csv...\n",
            "/ [6 files][  2.4 GiB/  2.4 GiB]   22.1 MiB/s                                   \n",
            "Operation completed over 6 objects/2.4 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrWSLBWHbR0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
        "# Modified to support timestamp type, categorical type\n",
        "# Modified to add option to use float16\n",
        "\n",
        "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
        "from pandas.api.types import is_categorical_dtype\n",
        "\n",
        "def reduce_mem_usage(df, use_float16=False):\n",
        "    \"\"\"\n",
        "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
        "    \"\"\"\n",
        "    \n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
        "    \n",
        "    for col in df.columns:\n",
        "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
        "            continue\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != object:\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            if str(col_type)[:3] == \"int\":\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)  \n",
        "            else:\n",
        "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                    df[col] = df[col].astype(np.float16)\n",
        "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    df[col] = df[col].astype(np.float64)\n",
        "        else:\n",
        "            df[col] = df[col].astype(\"category\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
        "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFJ7VQ2CNhrq",
        "colab_type": "code",
        "outputId": "61c418b1-898a-483b-995a-00a8534710b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "print(os.listdir('sample_data/'))\n",
        "data_path = 'sample_data/'\n",
        "train = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "test = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
        "building = pd.read_csv(os.path.join(data_path, 'building_metadata.csv'))\n",
        "weather_test = pd.read_csv(os.path.join(data_path, 'weather_test.csv'))\n",
        "#submission = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'))\n",
        "weather_train = pd.read_csv(os.path.join(data_path, 'weather_train.csv'))\n",
        "\n",
        "train = reduce_mem_usage(train, use_float16 = True)\n",
        "building = reduce_mem_usage(building, use_float16 = True)\n",
        "weather_train = reduce_mem_usage(weather_train, use_float16 = True)\n",
        "test = reduce_mem_usage(test)\n",
        "weather_test = reduce_mem_usage(weather_test)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['README.md', 'anscombe.json', 'train.csv', 'weather_train.csv', 'building_metadata.csv', 'weather_test.csv', 'test.csv', 'sample_submission.csv', 'mnist_train_small.csv', 'mnist_test.csv', 'california_housing_train.csv', 'california_housing_test.csv']\n",
            "Memory usage of dataframe is 616.95 MB\n",
            "Memory usage after optimization is: 173.90 MB\n",
            "Decreased by 71.8%\n",
            "Memory usage of dataframe is 0.07 MB\n",
            "Memory usage after optimization is: 0.02 MB\n",
            "Decreased by 73.8%\n",
            "Memory usage of dataframe is 9.60 MB\n",
            "Memory usage after optimization is: 2.65 MB\n",
            "Decreased by 72.4%\n",
            "Memory usage of dataframe is 1272.51 MB\n",
            "Memory usage after optimization is: 358.65 MB\n",
            "Decreased by 71.8%\n",
            "Memory usage of dataframe is 19.04 MB\n",
            "Memory usage after optimization is: 8.96 MB\n",
            "Decreased by 53.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUSj9_QobnlZ",
        "colab_type": "code",
        "outputId": "9659d23d-a54f-44b0-a7b2-66b830f601a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "print(train.head())\n",
        "print(train.shape)\n",
        "print('Building meta data: ')\n",
        "print(building.head())\n",
        "print('Weather meta data for building: ')\n",
        "print(weather_train.head())\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   building_id  meter            timestamp  meter_reading\n",
            "0            0      0  2016-01-01 00:00:00            0.0\n",
            "1            1      0  2016-01-01 00:00:00            0.0\n",
            "2            2      0  2016-01-01 00:00:00            0.0\n",
            "3            3      0  2016-01-01 00:00:00            0.0\n",
            "4            4      0  2016-01-01 00:00:00            0.0\n",
            "(20216100, 4)\n",
            "Building meta data: \n",
            "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
            "0        0            0   Education         7432      2008.0          NaN\n",
            "1        0            1   Education         2720      2004.0          NaN\n",
            "2        0            2   Education         5376      1991.0          NaN\n",
            "3        0            3   Education        23685      2002.0          NaN\n",
            "4        0            4   Education       116607      1975.0          NaN\n",
            "Weather meta data for building: \n",
            "   site_id            timestamp  ...  wind_direction  wind_speed\n",
            "0        0  2016-01-01 00:00:00  ...             0.0    0.000000\n",
            "1        0  2016-01-01 01:00:00  ...            70.0    1.500000\n",
            "2        0  2016-01-01 02:00:00  ...             0.0    0.000000\n",
            "3        0  2016-01-01 03:00:00  ...             0.0    0.000000\n",
            "4        0  2016-01-01 04:00:00  ...           250.0    2.599609\n",
            "\n",
            "[5 rows x 9 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFzpoW8ebuX8",
        "colab_type": "text"
      },
      "source": [
        "As to training data, I've about 1448 buildings to predict. \n",
        "Time scan over 3 years, each day as time step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcKqkMxmbsxz",
        "colab_type": "code",
        "outputId": "a1e5205e-6a22-45c8-a168-408ab73dcbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data engineering\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Category feaure encoding\n",
        "le = LabelEncoder()\n",
        "building['primary_use'] = le.fit_transform(building['primary_use'])\n",
        "\n",
        "# delete useless feature\n",
        "weather_train.drop(['sea_level_pressure', 'wind_direction', 'wind_speed'], axis = 1, inplace = True)\n",
        "weather_test.drop(['sea_level_pressure', 'wind_direction', 'wind_speed'], axis = 1, inplace = True)\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFvEyyEfbzt7",
        "colab_type": "text"
      },
      "source": [
        "Now should we rearrange the data? Each building locate in single site.\n",
        "Assumption to rearrange:\n",
        "1. Sort by building_id\n",
        "2. Sort by time_stamp\n",
        "\n",
        "Feature engineering:\n",
        "Data cleaning: delete useless column\n",
        "Data processing: standardization\n",
        "Feature engineering: create new features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvX0H7mEb0nO",
        "colab_type": "code",
        "outputId": "ef48773d-e71f-411a-b115-724f30f1a763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "'''\n",
        "# Reduce memory usage\n",
        "print(train.memory_usage().sum())\n",
        "print(building.memory_usage().sum())\n",
        "print(weather_train.memory_usage().sum())\n",
        "'''\n",
        "# Data Preprocessing\n",
        "def preprocessing(x, building_data, weather_data, test = False):\n",
        "    '''\n",
        "    Preprocessing for training and testing data:\n",
        "    Merge data with other two feature dataset\n",
        "    Create new useful features\n",
        "    Sort data by timestamp\n",
        "    \n",
        "    Return:\n",
        "    training: X & y\n",
        "    testing: X\n",
        "    '''\n",
        "    # Merge all feature data\n",
        "    X = x.merge(building_data, on = 'building_id', how = 'left')\n",
        "    X = X.merge(weather_data, on = ['site_id', 'timestamp'], how = 'left')\n",
        "    \n",
        "    # we create new feature from timestamp: assumed useful information in \n",
        "    # 3 time feature: hour, weekday, in_holiday\n",
        "    # Could validate this later\n",
        "    X['timestamp'] = pd.to_datetime(X['timestamp'], format = '%Y-%m-%d %H:%M:%S')\n",
        "    X['square_feet'] = np.log1p(X['square_feet'])\n",
        "    \n",
        "    # Sort training data by timestamp\n",
        "    if not test:\n",
        "        X.sort_values(by = 'timestamp', inplace = True) # sort train data by time\n",
        "        X.reset_index(drop = True, inplace = True)  # reset index to default that messed by sorting\n",
        "        \n",
        "    # holiday? Should I set holiday by hand? How to validate the association?\n",
        "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
        "                \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
        "                \"2017-01-01\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
        "                \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
        "                \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
        "                \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
        "                \"2019-01-01\"]\n",
        "    \n",
        "    X['hour'] = X['timestamp'].dt.hour\n",
        "    X['weekday'] = X['timestamp'].dt.dayofweek\n",
        "    #X[\"is_holiday\"] = (X.timestamp.dt.date.astype(\"str\").isin(holidays)).astype(int)\n",
        "    \n",
        "    # After create useful features from timestamp, remove if\n",
        "    X.drop('timestamp', axis = 1, inplace = True)\n",
        "    \n",
        "    # Return X & y\n",
        "    if not test:\n",
        "        y = np.log1p(X['meter_reading'])\n",
        "        X.drop('meter_reading', axis = 1, inplace = True)\n",
        "        return X, y\n",
        "    elif test == True:\n",
        "        row_id = X['row_id']\n",
        "        X.drop('row_id', axis = 1, inplace = True)\n",
        "        return X, row_id\n",
        "    \n",
        "## Q1: Should I do log transformation?\n",
        "## Q2: Should I set holiday by hand?\n",
        "## Q3: There are still columns contains multiple missing values\n",
        "\n",
        "# Create training data\n",
        "x_data, y_data = preprocessing(train, building, weather_train, False)\n",
        "del train, weather_train\n",
        "gc.collect()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpuWN6qhcATL",
        "colab_type": "code",
        "outputId": "521e8fd5-c78d-4f8e-b4c2-b2fc51dd5638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# 70% for training, 30% for validating\n",
        "train_end = int(len(x_data) * 0.5)\n",
        "x_train = x_data[0:train_end]\n",
        "x_valid = x_data[train_end:]\n",
        "y_train = y_data[0:train_end]\n",
        "y_valid = y_data[train_end:]\n",
        "\n",
        "# Specify categorical features for xgboost\n",
        "cat_feature = ['building_id', 'site_id', 'meter', 'primary_use', 'hour', 'weekday']\n",
        "train_set = lgb.Dataset(x_train, label = y_train, \n",
        "                        categorical_feature = cat_feature, \n",
        "                        free_raw_data = False\n",
        "                       )\n",
        "valid_set = lgb.Dataset(x_valid, label = y_valid,\n",
        "                       categorical_feature = cat_feature,\n",
        "                       free_raw_data = False)\n",
        "\n",
        "print('Create LGBM dataset, training on 70% of data and validate on 30% of data')\n",
        "params = {'task':'train',\n",
        "          'objective':'regression',\n",
        "          'boosting':'gbdt',\n",
        "          'num_iterations':1000,\n",
        "          'learning_rate':0.05,\n",
        "          'num_leaves':45,\n",
        "          'metric':'rmse',\n",
        "          'feature_fraction':0.8,\n",
        "          'reg_lambda':2\n",
        "         }\n",
        "train_booster = lgb.train(params,\n",
        "                          train_set = train_set,\n",
        "                          #num_boost_round = 1000,\n",
        "                          valid_sets = [train_set, valid_set],\n",
        "                          verbose_eval = 200,\n",
        "                          early_stopping_rounds = 200\n",
        "                         )\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create LGBM dataset, training on 70% of data and validate on 30% of data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/lightgbm/engine.py:118: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
            "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:1205: UserWarning: Using categorical_feature in Dataset.\n",
            "  warnings.warn('Using categorical_feature in Dataset.')\n",
            "/usr/local/lib/python3.6/dist-packages/lightgbm/basic.py:762: UserWarning: categorical_feature in param dict is overridden.\n",
            "  warnings.warn('categorical_feature in param dict is overridden.')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's rmse: 0.918024\tvalid_1's rmse: 1.33676\n",
            "[400]\ttraining's rmse: 0.8642\tvalid_1's rmse: 1.33928\n",
            "Early stopping, best iteration is:\n",
            "[313]\ttraining's rmse: 0.882021\tvalid_1's rmse: 1.33565\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "604"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16tLIaNicLAM",
        "colab_type": "code",
        "outputId": "4cd3e325-79bf-4bc5-8001-08459a87ce18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "del x_train, x_valid, y_train, y_valid, train_set, valid_set\n",
        "gc.collect()\n",
        "\n",
        "test_data, row_ids = preprocessing(test, building, weather_test, True)\n",
        "print(row_ids.head())\n",
        "\n",
        "del test, weather_test, building\n",
        "gc.collect()\n",
        "# Scoring test data\n",
        "prediction = train_booster.predict(data = test_data \n",
        "                                   #num_iteration = train_booster.best_iteration\n",
        "                                  )\n",
        "# Transform back from the log1p transformation on the y_data\n",
        "prediction = np.expm1(prediction)\n",
        "# limit the value minimum to zero, no negative\n",
        "prediction = np.clip(prediction, a_min = 0, a_max = None)\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0\n",
            "1    1\n",
            "2    2\n",
            "3    3\n",
            "4    4\n",
            "Name: row_id, dtype: int32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21NQKgSWSeAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cee37779-0f7b-4de0-a5f4-783270a63240"
      },
      "source": [
        "# save model for later comparison\n",
        "train_booster.save_model('lgbm_1')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Booster at 0x7f1eabcbb320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNE9VcISTOdh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ee918a9-3440-4ee6-dec6-353bd09580db"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "adc.json  lgbm_1  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HCWLs4yTyxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "9cf8d4b9-7abd-4724-d750-0bc873004f28"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('lgbm_1')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-72413806cb58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lgbm_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    }
  ]
}