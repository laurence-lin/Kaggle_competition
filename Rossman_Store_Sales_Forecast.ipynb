{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Rossman Store Sales Forecast.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laurence-lin/Kaggle_competition/blob/master/Rossman_Store_Sales_Forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "z-xcD87ulvvn",
        "colab_type": "code",
        "outputId": "6c030446-79f1-4308-e5dc-e367e2243301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%tensorflow_version 1.9\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import x\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.9`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F12zirYml4QS",
        "colab_type": "code",
        "outputId": "5a1c80c4-28c3-4fe5-dc61-56a71ff14513",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "\n",
        "%cd /root/\n",
        "!mkdir .kaggle\n",
        "%cd .kaggle\n",
        "files.upload()\n",
        "!kaggle competitions download -c rossmann-store-sales\n",
        "!unzip test.csv.zip\n",
        "!unzip train.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "mkdir: cannot create directory ‘.kaggle’: File exists\n",
            "/root/.kaggle\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4a8b42dd-b51b-4c09-8cc9-90811cc1899e\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4a8b42dd-b51b-4c09-8cc9-90811cc1899e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /root/.kaggle\n",
            " 75% 5.00M/6.71M [00:00<00:00, 47.8MB/s]\n",
            "100% 6.71M/6.71M [00:00<00:00, 42.8MB/s]\n",
            "Downloading sample_submission.csv to /root/.kaggle\n",
            "  0% 0.00/310k [00:00<?, ?B/s]\n",
            "100% 310k/310k [00:00<00:00, 92.3MB/s]\n",
            "Downloading test.csv.zip to /root/.kaggle\n",
            "  0% 0.00/192k [00:00<?, ?B/s]\n",
            "100% 192k/192k [00:00<00:00, 181MB/s]\n",
            "Downloading store.csv to /root/.kaggle\n",
            "  0% 0.00/44.0k [00:00<?, ?B/s]\n",
            "100% 44.0k/44.0k [00:00<00:00, 43.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc8LLe6bnFqH",
        "colab_type": "code",
        "outputId": "dc9e20b6-3b81-4d96-fa9b-009fdcfee5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "store = pd.read_csv('store.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a8b71f1e354c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'store.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XI8KxIa7lvvs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
        "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
        "         'StateHoliday': np.dtype(str),\n",
        "         'Promo2SinceWeek': np.dtype(int),\n",
        "         'SchoolHoliday': np.dtype(float),\n",
        "         'PromoInterval': np.dtype(str)}\n",
        "train = pd.read_csv(f\"{data}train.csv\", parse_dates=[2], dtype=types)\n",
        "print(train.info())\n",
        "\n",
        "'''\n",
        "train_date = train.Date.unique()\n",
        "print(train_date)\n",
        "print('Time scan of dataset', len(train_date))\n",
        "\n",
        "test_date = test.Date.unique()\n",
        "print(test_date)\n",
        "print('Time scan of test data', len(test_date))\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCYMO20clvvv",
        "colab_type": "text"
      },
      "source": [
        "Data description:\n",
        "Totally 942 days for whole dataset, 48 days to predict.\n",
        "\n",
        "In these 942 days, up to 1115 stores in each day(some store may )\n",
        "\n",
        "Training dataset: time line 2013.03.01-2015.07.31\n",
        "\n",
        "Testing dataset: time line 2015-08-01 to 2015-09-17\n",
        "\n",
        "Stores: 1115 different stores, each store contains 9 features for the store itself\n",
        "\n",
        "Target: predict daily sales 6 weeks in advance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KaGjmNWLlvvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store = pd.read_csv(data + 'store.csv')\n",
        "\n",
        "types = {'CompetitionOpenSinceYear': np.dtype(int),\n",
        "         'CompetitionOpenSinceMonth': np.dtype(int),\n",
        "         'StateHoliday': np.dtype(str),\n",
        "         'Promo2SinceWeek': np.dtype(int),\n",
        "         'SchoolHoliday': np.dtype(float),\n",
        "         'PromoInterval': np.dtype(str)}\n",
        "train = pd.read_csv(f\"{data}train.csv\", parse_dates=[2], dtype=types)\n",
        "test = pd.read_csv(f'{data}/test.csv', parse_dates = [3], dtype = types)\n",
        "print(train.info())\n",
        "\n",
        "# Consider only open store for training.\n",
        "print(train.shape)\n",
        "print('Consider only open store for training')\n",
        "train = train[train.Open == 1]\n",
        "print(train.shape)\n",
        "print('Consider only Sales >0, to simplify calculation of RMSPE')\n",
        "train = train[train.Sales > 0]\n",
        "print(train.shape)\n",
        "\n",
        "# Use merge to concat store to train & test set, while 'on' could fit the rows with 'Store'\n",
        "# merge() method, the two merge dataframe should have same column name and value to fit the merging\n",
        "train = pd.merge(train, store, on = 'Store')\n",
        "test = pd.merge(test, store, on = 'Store')\n",
        "print('Train + Store shape:', train.shape)\n",
        "print('Test + Store shape:', test.shape)\n",
        "\n",
        "features = []\n",
        "print(train.info())\n",
        "print(test.info())\n",
        "\n",
        "# fill in missing\n",
        "obj_feature = train.select_dtypes(exclude = ['int', 'float'])\n",
        "obj_name = obj_feature.columns.values\n",
        "print(obj_name)\n",
        "\n",
        "#for i in range(len(obj_name)):\n",
        " #   print(obj_name[i])\n",
        "  #  print(obj_feature[obj_name[i]].unique())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zkGIN6wAlvvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_ = train.drop(['Date', 'Open'], axis = 1)\n",
        "corr = data_.corr()\n",
        "\n",
        "sns.heatmap(corr)\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VcIxiezZlvv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_sales = corr['Sales'].sort_values(ascending = False)\n",
        "print(corr_sales)\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5gH0wSzZlvv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_null = (train.isnull().sum()/len(train)) * 100\n",
        "print(train_null[train_null > 0])\n",
        "train_null = train_null[train_null > 0]\n",
        "train_null.sort_values(ascending = False, inplace = True)\n",
        "#print('Train missing:\\n', train_null)\n",
        "\n",
        "train_fill = train[train_null.index]\n",
        "#print(train_fill.info())\n",
        "\n",
        "# Plot pair plot: While under different categorical features values, \n",
        "# the relationship of each features\n",
        "obj = train.select_dtypes(include = 'object')\n",
        "obj_feature = obj.columns.values\n",
        "\n",
        "'''\n",
        "for feat in obj_feature:\n",
        "    not_null = [col for col in train.columns if col not in train_fill.columns]\n",
        "    train_ = train[not_null]\n",
        "    print(train_.columns)\n",
        "    plt.figure()\n",
        "    sns.pairplot(train_, hue = feat)\n",
        "    plt.show()\n",
        "'''\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "l46pgCVflvv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "print(test.Date.head())\n",
        "print(train.Date.head())\n",
        "\n",
        "# Create optimal features by feature engineering\n",
        "def build_feature(data):\n",
        "    # Feature engineering: add new features\n",
        "    features = []\n",
        "    data.fillna(0, inplace = True)\n",
        "    \n",
        "    encode_feature = ['StateHoliday', 'StoreType', 'Assortment']\n",
        "    encoder = LabelEncoder()\n",
        "    for i in range(len(encode_feature)):\n",
        "        data[encode_feature[i]] = encoder.fit_transform(data[encode_feature[i]])\n",
        "        \n",
        "    features.extend(['Store', 'StateHoliday', 'StoreType', 'Assortment'])\n",
        "    \n",
        "    # Add datetime feature\n",
        "    date = data.Date\n",
        "    data['Year'] = data.Date.dt.year\n",
        "    data['month'] = date.dt.month\n",
        "    data['day'] = date.dt.day\n",
        "    data['dayofweek'] = date.dt.dayofweek\n",
        "    data['weekofyear'] = date.dt.weekofyear\n",
        "    \n",
        "    features.extend(['Year', 'month', 'day', 'dayofweek', 'weekofyear'])\n",
        "    \n",
        "    # Add in new features for competition of the store: combine the past compitition Open since Year & month\n",
        "    data['CompetitionOpen'] = 12*(data.Year - data.CompetitionOpenSinceYear) + \\\n",
        "    (data.month - data.CompetitionOpenSinceMonth)\n",
        "    # unit: past time of month\n",
        "    # Use month as time interval unit: do not make feature value too large\n",
        "    data['Promo2Open'] = (data.weekofyear - data.Promo2SinceWeek)/4 + 12*(data.Year - data.Promo2SinceYear) \n",
        "    mapping = {'Jan,Apr,Jul,Oct':1, 'Feb,May,Aug,Nov':2}\n",
        "    data['Promo2Start'] = data.PromoInterval.map(mapping)\n",
        "    data.fillna(0, inplace = True)\n",
        "    features.extend(['CompetitionOpen', 'Promo2Open', 'Promo2Start'])\n",
        "    \n",
        "    return data, features\n",
        "\n",
        "'''\n",
        "def feature_engineer(data):\n",
        "    data.Year = data.Year - 2000\n",
        "    scaler = MinMaxScaler()\n",
        "    data['CompetitionOpen'] = scaler.fit_transform( data['CompetitionOpen'].values.reshape(-1, 1))\n",
        "    data['Promo2Open'] = scaler.fit_transform(data['Promo2Open'].values.reshape(-1, 1))\n",
        "    data.drop('Store', axis = 1, inplace = True)\n",
        "    #print(data.columns)\n",
        "    scale_feature = ['Year', 'month', 'day', 'weekofyear']\n",
        "    data['dayofweek'] *= 0.1\n",
        "    data[scale_feature] *= 0.01\n",
        "\n",
        "    return data\n",
        "'''\n",
        "\n",
        "train, features = build_feature(train)\n",
        "test, _ = build_feature(test)\n",
        "print('Training set and Test set feature pre-processed') \n",
        "\n",
        "# Get the x & y matrix from specific features\n",
        "y = train['Sales']\n",
        "x = train[features]\n",
        "x_test = test[features]\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mseXyORRlvwB",
        "colab_type": "text"
      },
      "source": [
        "After feature engineering, convert time series data to time pipeline with shape:\n",
        "[batch size, time step, n_features] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Bgy6KYC4lvwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Convert data into time series pipeline: ')\n",
        "#print(x_train.values.shape)\n",
        "#print(x_train.iloc[0, :].shape)\n",
        "gc.collect()\n",
        "# Create time pipeline for LSTM network\n",
        "def create_pipeline(data, target, time_step = 3):\n",
        "    # Use t ~ (t + t_delta) features to predict Sales on time (t + t_delta)\n",
        "    # data: [batch size, features]\n",
        "    # target: [batch_size], output target of each data sample\n",
        "    # time_step: number of past time step to predict future\n",
        "    # return: time pipeline of data size [batch size_, time_step, features] and target\n",
        "    pipeline = []\n",
        "    for t in range(len(data) - time_step + 1):\n",
        "        #print(data[0].shape)\n",
        "        pipeline.append(np.array(data[t:(t + time_step)]))\n",
        "    \n",
        "    target = target[(time_step - 1):]\n",
        "    pipeline = np.array(pipeline)\n",
        "   \n",
        "    return pipeline, target\n",
        "\n",
        "time_step = 10\n",
        "x, y = create_pipeline(x, y, time_step)\n",
        "print('Training set converted to time pipeline')\n",
        "print('Train data after convert: ', x.shape)\n",
        "print('Train target after convert: ', y.shape)\n",
        "\n",
        "gc.collect()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gysp5ZS3lvwF",
        "colab_type": "text"
      },
      "source": [
        "After feature engineering and time pipeline created, we could start build our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xq5TRlzclvwF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the prediction model: LSTM\n",
        "def create_model(time_step, input_features):\n",
        "    '''\n",
        "    Time series forecasting model\n",
        "    '''\n",
        "    model = keras.models.Sequential()\n",
        "    # input shape to LSTM layer: [batch size, time step, features]\n",
        "    model.add(keras.layers.LSTM(units = 20, input_shape = (time_step, input_features))) \n",
        "    model.add(keras.layers.Dense(1, activation = tf.nn.relu))\n",
        "    \n",
        "    return model\n",
        "\n",
        "seed = 9\n",
        "x_train, x_valid, y_train , y_valid = train_test_split(x, y, test_size = 0.2, \n",
        "                                                       random_state = seed)\n",
        "\n",
        "input_features = x_train.shape[-1]\n",
        "'''\n",
        "model = create_model(time_step, input_features)\n",
        "model.compile(optimizer = tf.train.AdamOptimizer(1e-3),\n",
        "             loss = 'mse',\n",
        "             metrics = ['mse'])\n",
        "'''\n",
        "model = keras.models.load_model('../input/lstm-model/lstm_model.h5')\n",
        "model.compile(optimizer = tf.train.AdamOptimizer(1e-3),\n",
        "             loss = 'mse',\n",
        "             metrics = ['mse'])\n",
        "# Save checkpoint model during training\n",
        "filepath = 'lstm_model.hdf5'\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, \n",
        "                                                monitor = 'val_loss', \n",
        "                                                save_best_only = True,\n",
        "                                                mode = 'min', # while val_loss is minimum\n",
        "                                                period = 5,\n",
        "                                                verbose = 1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss',\n",
        "                                                mode = 'min',\n",
        "                                                patience = 5)\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs = 100,\n",
        "            shuffle = True,\n",
        "            validation_data = (x_valid, y_valid),\n",
        "            callbacks = [checkpoint, earlystopping])\n",
        "\n",
        "model.save('lstm_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PosASxuolvwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define parameters of xgboost\n",
        "param = {\n",
        "    'booster':'gbtree',\n",
        "    'eta': 0.3,  # learning rate\n",
        "    'gamma':0,  # minimal loss to split leaf\n",
        "    'max_depth':10,\n",
        "    'predictor':'gpu_predictor'\n",
        "        }\n",
        "\n",
        "# Split train and valid data\n",
        "seed = 9\n",
        "x_train, x_valid = train_test_split(train, test_size = 0.2, random_state = seed)\n",
        "# input of xgboost should be dmatrix\n",
        "\n",
        "\n",
        "print(features)\n",
        "\n",
        "dtrain = xgb.DMatrix(x_train[features], label = x_train.Sales)\n",
        "dvalid = xgb.DMatrix(x_valid[features], label = x_valid.Sales)\n",
        "print(x_train.columns)\n",
        "\n",
        "num_round = 300\n",
        "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
        "# Training\n",
        "#regressor = xgb.train(param, dtrain, num_round, evals = watchlist, early_stopping_rounds = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pMSBuR3BlvwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_valid)\n",
        "\n",
        "\n",
        "y_pred = np.squeeze(y_pred)\n",
        "rmse = np.sqrt(sum((np.squeeze(y_pred) - y_true)**2))/len(y_true)\n",
        "print('RMSE:', rmse)\n",
        "\n",
        "y_pred = y_pred.ravel()\n",
        "y_true = y_true.ravel()\n",
        "print(y_pred[0:20])\n",
        "plt.plot(y_pred[0:20], color = 'red', label = 'predicted value')\n",
        "plt.plot(y_true[0:20], color = 'blue', label = 'true value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vnrbU94FlvwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate validate accuracy and show the result\n",
        "print('Validating')\n",
        "\n",
        "y_pred = regressor.predict(dvalid)\n",
        "rmse = np.sqrt(sum((y_pred - x_valid.Sales)**2))/len(y_pred)\n",
        "print('RMSE:', rmse)\n",
        "\n",
        "print(x_valid.Sales.values.shape)\n",
        "\n",
        "plt.plot(x_valid.Sales.values[0:10000], color = 'red')\n",
        "plt.plot(y_pred[0:10000], color = 'blue')\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hU4aubEHlvwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test = xgb.DMatrix(test[features])\n",
        "prediction = regressor.predict(test)\n",
        "submit = '/kaggle/input/sample_submission.csv'\n",
        "submit = pd.read_csv(submit)\n",
        "print(submit.head())\n",
        "submit.Sales = prediction\n",
        "submit.to_csv('submission.csv')\n",
        "print(submit.head())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_vV8RuohlvwT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the modules we'll need\n",
        "from IPython.display import HTML\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import base64\n",
        "\n",
        "# function that takes in a dataframe and creates a text link to  \n",
        "# download it (will only work for files < 2MB or so)\n",
        "def create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n",
        "    csv = df.to_csv()\n",
        "    b64 = base64.b64encode(csv.encode())\n",
        "    payload = b64.decode()\n",
        "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
        "    html = html.format(payload=payload,title=title,filename=filename)\n",
        "    return HTML(html)\n",
        "\n",
        "\n",
        "# create a link to download the dataframe\n",
        "create_download_link(submit)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}